{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a823fa8",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02b0610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 19:39:27.423069: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747067967.525346   80307 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747067967.555504   80307 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747067967.771051   80307 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747067967.771098   80307 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747067967.771101   80307 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747067967.771104   80307 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-12 19:39:27.801974: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist, cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "num_classes = y_train.max()-y_train.min()+1\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db764240",
   "metadata": {},
   "source": [
    "### NN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de8158e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pixels = x_test.shape[1]*x_test.shape[2]\n",
    "x_train_resh = x_train.reshape((x_train.shape[0], num_pixels))\n",
    "x_test_resh = x_test.reshape((x_test.shape[0], num_pixels))\n",
    "x_train_resh.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a38241e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 19:39:35.278568: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "inputs = Input(shape=(x_train_resh.shape[1],))\n",
    "x = Dense(512, activation=\"relu\")(inputs)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dense(10, activation=\"softmax\")(x)\n",
    "model0 = Model(inputs=inputs, outputs=x)\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7a2ad16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.8664 - loss: 0.4717 - precision: 0.9306 - recall: 0.7859 - val_accuracy: 0.9605 - val_loss: 0.1335 - val_precision: 0.9680 - val_recall: 0.9545\n",
      "Epoch 2/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9714 - loss: 0.0947 - precision: 0.9760 - recall: 0.9667 - val_accuracy: 0.9565 - val_loss: 0.1392 - val_precision: 0.9611 - val_recall: 0.9523\n",
      "Epoch 3/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9806 - loss: 0.0605 - precision: 0.9836 - recall: 0.9783 - val_accuracy: 0.9717 - val_loss: 0.0936 - val_precision: 0.9744 - val_recall: 0.9700\n",
      "Epoch 4/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9893 - loss: 0.0357 - precision: 0.9905 - recall: 0.9877 - val_accuracy: 0.9756 - val_loss: 0.0872 - val_precision: 0.9781 - val_recall: 0.9734\n",
      "Epoch 5/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9912 - loss: 0.0276 - precision: 0.9923 - recall: 0.9904 - val_accuracy: 0.9719 - val_loss: 0.0955 - val_precision: 0.9745 - val_recall: 0.9702\n",
      "Epoch 6/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9938 - loss: 0.0189 - precision: 0.9945 - recall: 0.9933 - val_accuracy: 0.9758 - val_loss: 0.0877 - val_precision: 0.9775 - val_recall: 0.9750\n",
      "Epoch 7/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9950 - loss: 0.0157 - precision: 0.9953 - recall: 0.9946 - val_accuracy: 0.9756 - val_loss: 0.1008 - val_precision: 0.9777 - val_recall: 0.9747\n",
      "Epoch 8/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9959 - loss: 0.0125 - precision: 0.9961 - recall: 0.9957 - val_accuracy: 0.9769 - val_loss: 0.0962 - val_precision: 0.9783 - val_recall: 0.9762\n",
      "Epoch 9/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9965 - loss: 0.0110 - precision: 0.9966 - recall: 0.9963 - val_accuracy: 0.9677 - val_loss: 0.1428 - val_precision: 0.9698 - val_recall: 0.9669\n",
      "Epoch 10/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9938 - loss: 0.0192 - precision: 0.9942 - recall: 0.9932 - val_accuracy: 0.9762 - val_loss: 0.0992 - val_precision: 0.9776 - val_recall: 0.9757\n",
      "Epoch 11/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9969 - loss: 0.0092 - precision: 0.9971 - recall: 0.9968 - val_accuracy: 0.9749 - val_loss: 0.1137 - val_precision: 0.9763 - val_recall: 0.9743\n",
      "Epoch 12/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9972 - loss: 0.0087 - precision: 0.9973 - recall: 0.9971 - val_accuracy: 0.9757 - val_loss: 0.1117 - val_precision: 0.9764 - val_recall: 0.9749\n",
      "Epoch 13/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9972 - loss: 0.0096 - precision: 0.9973 - recall: 0.9971 - val_accuracy: 0.9741 - val_loss: 0.1209 - val_precision: 0.9751 - val_recall: 0.9735\n",
      "Epoch 14/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9938 - loss: 0.0179 - precision: 0.9941 - recall: 0.9934 - val_accuracy: 0.9773 - val_loss: 0.1078 - val_precision: 0.9780 - val_recall: 0.9768\n",
      "Epoch 15/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9980 - loss: 0.0054 - precision: 0.9981 - recall: 0.9979 - val_accuracy: 0.9756 - val_loss: 0.1229 - val_precision: 0.9764 - val_recall: 0.9751\n",
      "Epoch 16/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9991 - loss: 0.0035 - precision: 0.9991 - recall: 0.9990 - val_accuracy: 0.9762 - val_loss: 0.1236 - val_precision: 0.9770 - val_recall: 0.9757\n",
      "Epoch 17/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9976 - loss: 0.0069 - precision: 0.9977 - recall: 0.9976 - val_accuracy: 0.9721 - val_loss: 0.1384 - val_precision: 0.9731 - val_recall: 0.9713\n",
      "Epoch 18/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9965 - loss: 0.0106 - precision: 0.9967 - recall: 0.9965 - val_accuracy: 0.9781 - val_loss: 0.1210 - val_precision: 0.9786 - val_recall: 0.9777\n",
      "Epoch 19/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9980 - loss: 0.0062 - precision: 0.9981 - recall: 0.9980 - val_accuracy: 0.9785 - val_loss: 0.1123 - val_precision: 0.9791 - val_recall: 0.9781\n",
      "Epoch 20/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9984 - loss: 0.0047 - precision: 0.9985 - recall: 0.9984 - val_accuracy: 0.9799 - val_loss: 0.1159 - val_precision: 0.9802 - val_recall: 0.9795\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9806 - loss: 0.1119 - precision: 0.9813 - recall: 0.9804\n",
      "accuracy: 0.983299970626831,\n",
      " precision: 0.9838871359825134,\n",
      " recall: 0.9830999970436096\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "[[ 963    1    2    0    1    3    5    1    3    1]\n",
      " [   0 1128    1    0    0    1    1    1    3    0]\n",
      " [   2    0 1015    1    3    0    0    6    5    0]\n",
      " [   0    0    6  986    1    4    0    5    4    4]\n",
      " [   0    0    3    0  960    0    3    1    0   15]\n",
      " [   2    0    0    7    1  874    3    0    3    2]\n",
      " [   1    2    0    1    4    3  946    0    1    0]\n",
      " [   0    1    6    3    0    0    0 1012    4    2]\n",
      " [   1    0    4    3    1    1    1    3  956    4]\n",
      " [   0    3    0    0    5    1    0    4    3  993]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.99      0.98      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.99      0.98      0.98       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.97      0.98      0.98       974\n",
      "           9       0.97      0.98      0.98      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "model0.compile(optimizer='adam',loss='categorical_crossentropy',\n",
    "              metrics=['accuracy','precision','recall'])\n",
    "model0.fit(x_train_resh, y_train, epochs=20, batch_size=128, validation_split=0.25, verbose=1)\n",
    "loss, acc, prec, rec = model0.evaluate(x_test_resh,y_test)\n",
    "print(f'accuracy: {acc},\\n precision: {prec},\\n recall: {rec}')\n",
    "\n",
    "pred = model0.predict(x_test_resh)\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "y_test0 = np.argmax(y_test, axis=1)\n",
    "print(confusion_matrix(y_test0,y_pred))\n",
    "print(classification_report(y_test0, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c6246",
   "metadata": {},
   "source": [
    "### CNN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ae4728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,530</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m11,530\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,202</span> (407.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,202\u001b[0m (407.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,202</span> (407.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m104,202\u001b[0m (407.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D, Flatten\n",
    "\n",
    "inputs = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(10, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa34456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 65ms/step - accuracy: 0.8206 - loss: 0.6383 - precision: 0.9032 - recall: 0.7022 - val_accuracy: 0.9753 - val_loss: 0.0868 - val_precision: 0.9794 - val_recall: 0.9709\n",
      "Epoch 2/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.9784 - loss: 0.0733 - precision: 0.9820 - recall: 0.9741 - val_accuracy: 0.9819 - val_loss: 0.0620 - val_precision: 0.9846 - val_recall: 0.9803\n",
      "Epoch 3/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 62ms/step - accuracy: 0.9864 - loss: 0.0448 - precision: 0.9879 - recall: 0.9849 - val_accuracy: 0.9825 - val_loss: 0.0553 - val_precision: 0.9842 - val_recall: 0.9814\n",
      "Epoch 4/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.9883 - loss: 0.0362 - precision: 0.9895 - recall: 0.9876 - val_accuracy: 0.9787 - val_loss: 0.0649 - val_precision: 0.9810 - val_recall: 0.9770\n",
      "Epoch 5/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.9897 - loss: 0.0309 - precision: 0.9909 - recall: 0.9889 - val_accuracy: 0.9856 - val_loss: 0.0492 - val_precision: 0.9866 - val_recall: 0.9851\n",
      "Epoch 6/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 62ms/step - accuracy: 0.9925 - loss: 0.0228 - precision: 0.9933 - recall: 0.9918 - val_accuracy: 0.9877 - val_loss: 0.0419 - val_precision: 0.9887 - val_recall: 0.9872\n",
      "Epoch 7/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - accuracy: 0.9940 - loss: 0.0184 - precision: 0.9948 - recall: 0.9933 - val_accuracy: 0.9878 - val_loss: 0.0421 - val_precision: 0.9889 - val_recall: 0.9875\n",
      "Epoch 8/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.9945 - loss: 0.0160 - precision: 0.9948 - recall: 0.9942 - val_accuracy: 0.9875 - val_loss: 0.0441 - val_precision: 0.9881 - val_recall: 0.9869\n",
      "Epoch 9/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 67ms/step - accuracy: 0.9961 - loss: 0.0119 - precision: 0.9964 - recall: 0.9960 - val_accuracy: 0.9855 - val_loss: 0.0513 - val_precision: 0.9862 - val_recall: 0.9849\n",
      "Epoch 10/10\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.9960 - loss: 0.0125 - precision: 0.9963 - recall: 0.9957 - val_accuracy: 0.9880 - val_loss: 0.0456 - val_precision: 0.9885 - val_recall: 0.9875\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9866 - loss: 0.0392 - precision: 0.9872 - recall: 0.9864\n",
      "accuracy: 0.9897000193595886,\n",
      " precision: 0.990192174911499,\n",
      " recall: 0.9894000291824341\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',\n",
    "              metrics=['accuracy','precision','recall'])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.25, verbose=1)\n",
    "loss, acc, prec, rec = model.evaluate(x_test,y_test)\n",
    "print(f'accuracy: {acc},\\n precision: {prec},\\n recall: {rec}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2c991c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "[[ 973    0    2    0    0    0    2    2    1    0]\n",
      " [   0 1124    1    3    0    1    2    3    0    1]\n",
      " [   0    0 1027    1    0    0    0    3    1    0]\n",
      " [   0    0    1 1005    0    3    0    0    1    0]\n",
      " [   0    0    1    0  967    0    4    0    0   10]\n",
      " [   0    0    0    4    0  887    1    0    0    0]\n",
      " [   3    2    2    0    1    4  944    0    2    0]\n",
      " [   0    1    3    1    0    0    0 1018    1    4]\n",
      " [   2    0    2    4    1    3    0    3  950    9]\n",
      " [   2    0    0    0    1    3    0    1    0 1002]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       1.00      0.99      0.99      1135\n",
      "           2       0.99      1.00      0.99      1032\n",
      "           3       0.99      1.00      0.99      1010\n",
      "           4       1.00      0.98      0.99       982\n",
      "           5       0.98      0.99      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.99      0.99      0.99      1028\n",
      "           8       0.99      0.98      0.98       974\n",
      "           9       0.98      0.99      0.98      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509f412a",
   "metadata": {},
   "source": [
    "## FASHION MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96dc3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train2, y_train2), (x_test2, y_test2) = fashion_mnist.load_data()\n",
    "num_classes = y_train2.max()-y_train2.min()+1\n",
    "x_train2 = x_train2.astype(\"float32\") / 255\n",
    "x_test2 = x_test2.astype(\"float32\") / 255\n",
    "y_train2 = to_categorical(y_train2, num_classes)\n",
    "y_test2 = to_categorical(y_test2, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5eabe5",
   "metadata": {},
   "source": [
    "### NN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1350d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pixels = x_test2.shape[1]*x_test2.shape[2]\n",
    "x_train2_resh = x_train2.reshape((x_train2.shape[0], num_pixels))\n",
    "x_test2_resh = x_test2.reshape((x_test2.shape[0], num_pixels))\n",
    "x_train2_resh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e553464b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">803,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m803,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,462,538</span> (5.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,462,538\u001b[0m (5.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,462,538</span> (5.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,462,538\u001b[0m (5.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = Input(shape=(x_train2_resh.shape[1],)) \n",
    "x = Dense(1024, activation=\"relu\")(inputs)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dense(10, activation=\"softmax\")(x)\n",
    "model0_2 = Model(inputs=inputs, outputs=x)\n",
    "model0_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b162415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 35ms/step - accuracy: 0.7636 - loss: 0.6647 - precision: 0.8469 - recall: 0.6854 - val_accuracy: 0.8408 - val_loss: 0.4222 - val_precision: 0.8721 - val_recall: 0.8107\n",
      "Epoch 2/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.8638 - loss: 0.3714 - precision: 0.8931 - recall: 0.8336 - val_accuracy: 0.8658 - val_loss: 0.3623 - val_precision: 0.8947 - val_recall: 0.8398\n",
      "Epoch 3/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step - accuracy: 0.8795 - loss: 0.3251 - precision: 0.9039 - recall: 0.8570 - val_accuracy: 0.8757 - val_loss: 0.3401 - val_precision: 0.9011 - val_recall: 0.8507\n",
      "Epoch 4/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.8897 - loss: 0.3012 - precision: 0.9101 - recall: 0.8698 - val_accuracy: 0.8807 - val_loss: 0.3237 - val_precision: 0.8978 - val_recall: 0.8651\n",
      "Epoch 5/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.8928 - loss: 0.2846 - precision: 0.9122 - recall: 0.8747 - val_accuracy: 0.8741 - val_loss: 0.3526 - val_precision: 0.8968 - val_recall: 0.8509\n",
      "Epoch 6/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - accuracy: 0.8976 - loss: 0.2671 - precision: 0.9165 - recall: 0.8822 - val_accuracy: 0.8847 - val_loss: 0.3174 - val_precision: 0.9046 - val_recall: 0.8710\n",
      "Epoch 7/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step - accuracy: 0.9007 - loss: 0.2645 - precision: 0.9200 - recall: 0.8843 - val_accuracy: 0.8871 - val_loss: 0.3249 - val_precision: 0.9019 - val_recall: 0.8776\n",
      "Epoch 8/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - accuracy: 0.9102 - loss: 0.2365 - precision: 0.9253 - recall: 0.8978 - val_accuracy: 0.8862 - val_loss: 0.3215 - val_precision: 0.9009 - val_recall: 0.8756\n",
      "Epoch 9/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9140 - loss: 0.2239 - precision: 0.9274 - recall: 0.9028 - val_accuracy: 0.8823 - val_loss: 0.3412 - val_precision: 0.8971 - val_recall: 0.8705\n",
      "Epoch 10/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step - accuracy: 0.9177 - loss: 0.2127 - precision: 0.9288 - recall: 0.9079 - val_accuracy: 0.8857 - val_loss: 0.3289 - val_precision: 0.8999 - val_recall: 0.8704\n",
      "Epoch 11/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - accuracy: 0.9185 - loss: 0.2088 - precision: 0.9298 - recall: 0.9073 - val_accuracy: 0.8935 - val_loss: 0.3286 - val_precision: 0.9060 - val_recall: 0.8838\n",
      "Epoch 12/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.9190 - loss: 0.2088 - precision: 0.9308 - recall: 0.9095 - val_accuracy: 0.8947 - val_loss: 0.3084 - val_precision: 0.9072 - val_recall: 0.8841\n",
      "Epoch 13/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.9255 - loss: 0.1928 - precision: 0.9363 - recall: 0.9172 - val_accuracy: 0.8969 - val_loss: 0.3115 - val_precision: 0.9088 - val_recall: 0.8876\n",
      "Epoch 14/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 38ms/step - accuracy: 0.9292 - loss: 0.1813 - precision: 0.9376 - recall: 0.9217 - val_accuracy: 0.8924 - val_loss: 0.3210 - val_precision: 0.9052 - val_recall: 0.8812\n",
      "Epoch 15/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.9334 - loss: 0.1718 - precision: 0.9418 - recall: 0.9251 - val_accuracy: 0.8901 - val_loss: 0.3334 - val_precision: 0.9025 - val_recall: 0.8822\n",
      "Epoch 16/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - accuracy: 0.9346 - loss: 0.1687 - precision: 0.9424 - recall: 0.9277 - val_accuracy: 0.8924 - val_loss: 0.3691 - val_precision: 0.9000 - val_recall: 0.8865\n",
      "Epoch 17/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.9371 - loss: 0.1652 - precision: 0.9439 - recall: 0.9307 - val_accuracy: 0.8928 - val_loss: 0.3557 - val_precision: 0.9000 - val_recall: 0.8861\n",
      "Epoch 18/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 34ms/step - accuracy: 0.9413 - loss: 0.1510 - precision: 0.9474 - recall: 0.9365 - val_accuracy: 0.8977 - val_loss: 0.3437 - val_precision: 0.9065 - val_recall: 0.8915\n",
      "Epoch 19/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 34ms/step - accuracy: 0.9398 - loss: 0.1497 - precision: 0.9463 - recall: 0.9343 - val_accuracy: 0.8926 - val_loss: 0.3607 - val_precision: 0.9011 - val_recall: 0.8843\n",
      "Epoch 20/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.9418 - loss: 0.1526 - precision: 0.9469 - recall: 0.9355 - val_accuracy: 0.8939 - val_loss: 0.3583 - val_precision: 0.9021 - val_recall: 0.8867\n",
      "Epoch 21/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.9450 - loss: 0.1393 - precision: 0.9498 - recall: 0.9399 - val_accuracy: 0.8963 - val_loss: 0.3598 - val_precision: 0.9036 - val_recall: 0.8908\n",
      "Epoch 22/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.9497 - loss: 0.1323 - precision: 0.9548 - recall: 0.9449 - val_accuracy: 0.8914 - val_loss: 0.3805 - val_precision: 0.9025 - val_recall: 0.8828\n",
      "Epoch 23/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.9493 - loss: 0.1300 - precision: 0.9538 - recall: 0.9446 - val_accuracy: 0.8954 - val_loss: 0.4146 - val_precision: 0.9020 - val_recall: 0.8921\n",
      "Epoch 24/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.9538 - loss: 0.1155 - precision: 0.9575 - recall: 0.9504 - val_accuracy: 0.8938 - val_loss: 0.3809 - val_precision: 0.9036 - val_recall: 0.8859\n",
      "Epoch 25/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.9530 - loss: 0.1226 - precision: 0.9572 - recall: 0.9484 - val_accuracy: 0.8930 - val_loss: 0.3984 - val_precision: 0.8995 - val_recall: 0.8894\n",
      "Epoch 26/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.9555 - loss: 0.1157 - precision: 0.9589 - recall: 0.9524 - val_accuracy: 0.8929 - val_loss: 0.4152 - val_precision: 0.9007 - val_recall: 0.8887\n",
      "Epoch 27/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - accuracy: 0.9547 - loss: 0.1185 - precision: 0.9582 - recall: 0.9511 - val_accuracy: 0.8992 - val_loss: 0.3864 - val_precision: 0.9039 - val_recall: 0.8951\n",
      "Epoch 28/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - accuracy: 0.9594 - loss: 0.1038 - precision: 0.9632 - recall: 0.9564 - val_accuracy: 0.8929 - val_loss: 0.4397 - val_precision: 0.8970 - val_recall: 0.8901\n",
      "Epoch 29/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.9597 - loss: 0.1015 - precision: 0.9629 - recall: 0.9574 - val_accuracy: 0.8950 - val_loss: 0.4198 - val_precision: 0.8994 - val_recall: 0.8920\n",
      "Epoch 30/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - accuracy: 0.9606 - loss: 0.0996 - precision: 0.9633 - recall: 0.9579 - val_accuracy: 0.8967 - val_loss: 0.4437 - val_precision: 0.9014 - val_recall: 0.8939\n",
      "Epoch 31/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.9639 - loss: 0.0935 - precision: 0.9666 - recall: 0.9614 - val_accuracy: 0.8976 - val_loss: 0.4279 - val_precision: 0.9027 - val_recall: 0.8941\n",
      "Epoch 32/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - accuracy: 0.9656 - loss: 0.0914 - precision: 0.9677 - recall: 0.9629 - val_accuracy: 0.8957 - val_loss: 0.4556 - val_precision: 0.9004 - val_recall: 0.8934\n",
      "Epoch 33/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.9677 - loss: 0.0833 - precision: 0.9699 - recall: 0.9654 - val_accuracy: 0.8990 - val_loss: 0.4366 - val_precision: 0.9032 - val_recall: 0.8953\n",
      "Epoch 34/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.9673 - loss: 0.0837 - precision: 0.9692 - recall: 0.9653 - val_accuracy: 0.8976 - val_loss: 0.4686 - val_precision: 0.9016 - val_recall: 0.8945\n",
      "Epoch 35/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.9683 - loss: 0.0817 - precision: 0.9707 - recall: 0.9665 - val_accuracy: 0.8924 - val_loss: 0.5485 - val_precision: 0.8961 - val_recall: 0.8900\n",
      "Epoch 36/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.9690 - loss: 0.0819 - precision: 0.9708 - recall: 0.9675 - val_accuracy: 0.8886 - val_loss: 0.5416 - val_precision: 0.8920 - val_recall: 0.8865\n",
      "Epoch 37/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.9672 - loss: 0.0866 - precision: 0.9689 - recall: 0.9655 - val_accuracy: 0.8965 - val_loss: 0.4574 - val_precision: 0.9007 - val_recall: 0.8930\n",
      "Epoch 38/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.9729 - loss: 0.0701 - precision: 0.9745 - recall: 0.9713 - val_accuracy: 0.8927 - val_loss: 0.5289 - val_precision: 0.8961 - val_recall: 0.8909\n",
      "Epoch 39/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.9701 - loss: 0.0816 - precision: 0.9712 - recall: 0.9683 - val_accuracy: 0.8967 - val_loss: 0.5246 - val_precision: 0.8994 - val_recall: 0.8949\n",
      "Epoch 40/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.9746 - loss: 0.0664 - precision: 0.9764 - recall: 0.9733 - val_accuracy: 0.8964 - val_loss: 0.5352 - val_precision: 0.8994 - val_recall: 0.8944\n",
      "Epoch 41/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - accuracy: 0.9730 - loss: 0.0679 - precision: 0.9748 - recall: 0.9718 - val_accuracy: 0.8925 - val_loss: 0.5426 - val_precision: 0.8953 - val_recall: 0.8909\n",
      "Epoch 42/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - accuracy: 0.9749 - loss: 0.0677 - precision: 0.9766 - recall: 0.9735 - val_accuracy: 0.8957 - val_loss: 0.5263 - val_precision: 0.8985 - val_recall: 0.8937\n",
      "Epoch 43/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.9764 - loss: 0.0634 - precision: 0.9777 - recall: 0.9754 - val_accuracy: 0.8891 - val_loss: 0.5661 - val_precision: 0.8919 - val_recall: 0.8875\n",
      "Epoch 44/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.9774 - loss: 0.0605 - precision: 0.9788 - recall: 0.9760 - val_accuracy: 0.8958 - val_loss: 0.5739 - val_precision: 0.8981 - val_recall: 0.8938\n",
      "Epoch 45/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.9771 - loss: 0.0605 - precision: 0.9782 - recall: 0.9758 - val_accuracy: 0.8962 - val_loss: 0.5695 - val_precision: 0.8987 - val_recall: 0.8938\n",
      "Epoch 46/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 35ms/step - accuracy: 0.9807 - loss: 0.0513 - precision: 0.9814 - recall: 0.9800 - val_accuracy: 0.8966 - val_loss: 0.5672 - val_precision: 0.8990 - val_recall: 0.8950\n",
      "Epoch 47/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.9779 - loss: 0.0587 - precision: 0.9793 - recall: 0.9771 - val_accuracy: 0.8984 - val_loss: 0.6443 - val_precision: 0.9007 - val_recall: 0.8975\n",
      "Epoch 48/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 34ms/step - accuracy: 0.9791 - loss: 0.0527 - precision: 0.9801 - recall: 0.9786 - val_accuracy: 0.8905 - val_loss: 0.6984 - val_precision: 0.8925 - val_recall: 0.8896\n",
      "Epoch 49/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.9799 - loss: 0.0506 - precision: 0.9807 - recall: 0.9793 - val_accuracy: 0.8995 - val_loss: 0.6717 - val_precision: 0.9014 - val_recall: 0.8983\n",
      "Epoch 50/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - accuracy: 0.9822 - loss: 0.0493 - precision: 0.9829 - recall: 0.9817 - val_accuracy: 0.8975 - val_loss: 0.5507 - val_precision: 0.9010 - val_recall: 0.8963\n",
      "Epoch 51/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - accuracy: 0.9835 - loss: 0.0438 - precision: 0.9845 - recall: 0.9826 - val_accuracy: 0.8909 - val_loss: 0.6452 - val_precision: 0.8936 - val_recall: 0.8893\n",
      "Epoch 52/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.9809 - loss: 0.0511 - precision: 0.9816 - recall: 0.9807 - val_accuracy: 0.8938 - val_loss: 0.5910 - val_precision: 0.8963 - val_recall: 0.8917\n",
      "Epoch 53/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.9822 - loss: 0.0509 - precision: 0.9830 - recall: 0.9816 - val_accuracy: 0.8939 - val_loss: 0.6361 - val_precision: 0.8973 - val_recall: 0.8917\n",
      "Epoch 54/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.9854 - loss: 0.0405 - precision: 0.9862 - recall: 0.9849 - val_accuracy: 0.8995 - val_loss: 0.6518 - val_precision: 0.9011 - val_recall: 0.8985\n",
      "Epoch 55/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.9846 - loss: 0.0394 - precision: 0.9850 - recall: 0.9842 - val_accuracy: 0.8949 - val_loss: 0.6261 - val_precision: 0.8970 - val_recall: 0.8936\n",
      "Epoch 56/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - accuracy: 0.9827 - loss: 0.0438 - precision: 0.9838 - recall: 0.9821 - val_accuracy: 0.8957 - val_loss: 0.6550 - val_precision: 0.8980 - val_recall: 0.8940\n",
      "Epoch 57/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - accuracy: 0.9824 - loss: 0.0513 - precision: 0.9832 - recall: 0.9819 - val_accuracy: 0.8943 - val_loss: 0.6359 - val_precision: 0.8964 - val_recall: 0.8927\n",
      "Epoch 58/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step - accuracy: 0.9822 - loss: 0.0489 - precision: 0.9830 - recall: 0.9818 - val_accuracy: 0.8985 - val_loss: 0.6550 - val_precision: 0.9003 - val_recall: 0.8972\n",
      "Epoch 59/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - accuracy: 0.9866 - loss: 0.0343 - precision: 0.9870 - recall: 0.9861 - val_accuracy: 0.8937 - val_loss: 0.6556 - val_precision: 0.8956 - val_recall: 0.8919\n",
      "Epoch 60/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.9853 - loss: 0.0387 - precision: 0.9860 - recall: 0.9848 - val_accuracy: 0.8992 - val_loss: 0.6805 - val_precision: 0.9002 - val_recall: 0.8981\n",
      "Epoch 61/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - accuracy: 0.9861 - loss: 0.0395 - precision: 0.9864 - recall: 0.9856 - val_accuracy: 0.8970 - val_loss: 0.6588 - val_precision: 0.8983 - val_recall: 0.8954\n",
      "Epoch 62/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - accuracy: 0.9864 - loss: 0.0363 - precision: 0.9870 - recall: 0.9860 - val_accuracy: 0.8913 - val_loss: 0.7373 - val_precision: 0.8938 - val_recall: 0.8906\n",
      "Epoch 63/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - accuracy: 0.9841 - loss: 0.0429 - precision: 0.9850 - recall: 0.9837 - val_accuracy: 0.8885 - val_loss: 0.7821 - val_precision: 0.8901 - val_recall: 0.8873\n",
      "Epoch 64/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 38ms/step - accuracy: 0.9828 - loss: 0.0488 - precision: 0.9835 - recall: 0.9824 - val_accuracy: 0.9005 - val_loss: 0.7080 - val_precision: 0.9019 - val_recall: 0.8996\n",
      "Epoch 65/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.9904 - loss: 0.0260 - precision: 0.9906 - recall: 0.9899 - val_accuracy: 0.8934 - val_loss: 0.7661 - val_precision: 0.8948 - val_recall: 0.8927\n",
      "Epoch 66/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.9859 - loss: 0.0389 - precision: 0.9865 - recall: 0.9857 - val_accuracy: 0.8952 - val_loss: 0.6901 - val_precision: 0.8968 - val_recall: 0.8933\n",
      "Epoch 67/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - accuracy: 0.9854 - loss: 0.0374 - precision: 0.9860 - recall: 0.9852 - val_accuracy: 0.8928 - val_loss: 0.7073 - val_precision: 0.8948 - val_recall: 0.8919\n",
      "Epoch 68/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - accuracy: 0.9881 - loss: 0.0319 - precision: 0.9883 - recall: 0.9878 - val_accuracy: 0.8979 - val_loss: 0.7333 - val_precision: 0.8989 - val_recall: 0.8971\n",
      "Epoch 69/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.9883 - loss: 0.0325 - precision: 0.9887 - recall: 0.9881 - val_accuracy: 0.8937 - val_loss: 0.7376 - val_precision: 0.8959 - val_recall: 0.8925\n",
      "Epoch 70/70\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - accuracy: 0.9878 - loss: 0.0338 - precision: 0.9881 - recall: 0.9876 - val_accuracy: 0.8948 - val_loss: 0.7826 - val_precision: 0.8958 - val_recall: 0.8943\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8884 - loss: 0.8434 - precision: 0.8897 - recall: 0.8874\n",
      "accuracy: 0.8920999765396118,\n",
      " precision: 0.8933547139167786,\n",
      " recall: 0.8913000226020813\n"
     ]
    }
   ],
   "source": [
    "model0_2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", \n",
    "                 metrics=['accuracy','precision','recall'])\n",
    "model0_2.fit(x_train2_resh, y_train2, epochs=70, batch_size=128, validation_split=0.25, verbose=1)\n",
    "loss, acc, prec, rec = model0_2.evaluate(x_test2_resh,y_test2)\n",
    "print(f'accuracy: {acc},\\n precision: {prec},\\n recall: {rec}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4765521f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "[[842   1  16  17   3   1 112   0   8   0]\n",
      " [  1 980   2   7   4   0   5   0   1   0]\n",
      " [ 26   0 843   8  59   0  64   0   0   0]\n",
      " [ 21   5  15 907  26   0  22   0   4   0]\n",
      " [  0   1 111  35 765   0  87   0   1   0]\n",
      " [  0   0   0   0   0 970   0  21   0   9]\n",
      " [115   0  76  35  44   0 720   0  10   0]\n",
      " [  0   0   0   0   0   6   0 957   0  37]\n",
      " [  3   0   5   5   2   1   4   5 975   0]\n",
      " [  0   0   0   0   0   7   1  30   0 962]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      1000\n",
      "           1       0.99      0.98      0.99      1000\n",
      "           2       0.79      0.84      0.82      1000\n",
      "           3       0.89      0.91      0.90      1000\n",
      "           4       0.85      0.77      0.80      1000\n",
      "           5       0.98      0.97      0.98      1000\n",
      "           6       0.71      0.72      0.71      1000\n",
      "           7       0.94      0.96      0.95      1000\n",
      "           8       0.98      0.97      0.98      1000\n",
      "           9       0.95      0.96      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred2 = model0_2.predict(x_test2_resh)\n",
    "y_pred2 = np.argmax(pred2, axis=1)\n",
    "y_test02 = np.argmax(y_test2, axis=1)\n",
    "print(confusion_matrix(y_test02,y_pred2))\n",
    "print(classification_report(y_test02, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1070fa7",
   "metadata": {},
   "source": [
    "### CNN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c6c130a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,530</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m11,530\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,202</span> (407.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,202\u001b[0m (407.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,202</span> (407.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m104,202\u001b[0m (407.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(10, activation=\"softmax\")(x)\n",
    "model2 = Model(inputs=inputs, outputs=outputs)\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7f0622c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 74ms/step - accuracy: 0.6724 - loss: 0.9457 - precision: 0.8136 - recall: 0.5132 - val_accuracy: 0.8349 - val_loss: 0.4476 - val_precision: 0.8782 - val_recall: 0.7899\n",
      "Epoch 2/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 72ms/step - accuracy: 0.8462 - loss: 0.4201 - precision: 0.8809 - recall: 0.8093 - val_accuracy: 0.8630 - val_loss: 0.3779 - val_precision: 0.8866 - val_recall: 0.8417\n",
      "Epoch 3/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 68ms/step - accuracy: 0.8768 - loss: 0.3498 - precision: 0.9011 - recall: 0.8529 - val_accuracy: 0.8805 - val_loss: 0.3319 - val_precision: 0.9024 - val_recall: 0.8601\n",
      "Epoch 4/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 67ms/step - accuracy: 0.8871 - loss: 0.3090 - precision: 0.9078 - recall: 0.8693 - val_accuracy: 0.8840 - val_loss: 0.3157 - val_precision: 0.9027 - val_recall: 0.8665\n",
      "Epoch 5/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.8964 - loss: 0.2855 - precision: 0.9138 - recall: 0.8795 - val_accuracy: 0.8915 - val_loss: 0.2983 - val_precision: 0.9116 - val_recall: 0.8755\n",
      "Epoch 6/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 67ms/step - accuracy: 0.9020 - loss: 0.2706 - precision: 0.9200 - recall: 0.8870 - val_accuracy: 0.8893 - val_loss: 0.3007 - val_precision: 0.9043 - val_recall: 0.8774\n",
      "Epoch 7/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 67ms/step - accuracy: 0.9063 - loss: 0.2559 - precision: 0.9213 - recall: 0.8928 - val_accuracy: 0.8887 - val_loss: 0.2943 - val_precision: 0.9028 - val_recall: 0.8791\n",
      "Epoch 8/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.9158 - loss: 0.2307 - precision: 0.9288 - recall: 0.9028 - val_accuracy: 0.9047 - val_loss: 0.2633 - val_precision: 0.9202 - val_recall: 0.8921\n",
      "Epoch 9/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 68ms/step - accuracy: 0.9195 - loss: 0.2200 - precision: 0.9327 - recall: 0.9077 - val_accuracy: 0.8975 - val_loss: 0.2853 - val_precision: 0.9090 - val_recall: 0.8862\n",
      "Epoch 10/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 69ms/step - accuracy: 0.9242 - loss: 0.2075 - precision: 0.9360 - recall: 0.9136 - val_accuracy: 0.9036 - val_loss: 0.2623 - val_precision: 0.9187 - val_recall: 0.8911\n",
      "Epoch 11/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.9315 - loss: 0.1946 - precision: 0.9420 - recall: 0.9219 - val_accuracy: 0.9062 - val_loss: 0.2590 - val_precision: 0.9186 - val_recall: 0.8974\n",
      "Epoch 12/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.9343 - loss: 0.1816 - precision: 0.9438 - recall: 0.9258 - val_accuracy: 0.9103 - val_loss: 0.2552 - val_precision: 0.9215 - val_recall: 0.9010\n",
      "Epoch 13/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 68ms/step - accuracy: 0.9402 - loss: 0.1638 - precision: 0.9495 - recall: 0.9324 - val_accuracy: 0.9103 - val_loss: 0.2553 - val_precision: 0.9220 - val_recall: 0.9013\n",
      "Epoch 14/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9432 - loss: 0.1566 - precision: 0.9512 - recall: 0.9362 - val_accuracy: 0.9065 - val_loss: 0.2655 - val_precision: 0.9169 - val_recall: 0.8979\n",
      "Epoch 15/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 68ms/step - accuracy: 0.9454 - loss: 0.1486 - precision: 0.9533 - recall: 0.9386 - val_accuracy: 0.9160 - val_loss: 0.2524 - val_precision: 0.9246 - val_recall: 0.9097\n",
      "Epoch 16/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 68ms/step - accuracy: 0.9526 - loss: 0.1326 - precision: 0.9592 - recall: 0.9473 - val_accuracy: 0.9128 - val_loss: 0.2620 - val_precision: 0.9199 - val_recall: 0.9063\n",
      "Epoch 17/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 62ms/step - accuracy: 0.9552 - loss: 0.1243 - precision: 0.9614 - recall: 0.9505 - val_accuracy: 0.9115 - val_loss: 0.2655 - val_precision: 0.9207 - val_recall: 0.9065\n",
      "Epoch 18/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 71ms/step - accuracy: 0.9566 - loss: 0.1187 - precision: 0.9617 - recall: 0.9523 - val_accuracy: 0.9144 - val_loss: 0.2640 - val_precision: 0.9223 - val_recall: 0.9097\n",
      "Epoch 19/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 72ms/step - accuracy: 0.9605 - loss: 0.1122 - precision: 0.9646 - recall: 0.9557 - val_accuracy: 0.9133 - val_loss: 0.2862 - val_precision: 0.9204 - val_recall: 0.9075\n",
      "Epoch 20/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 67ms/step - accuracy: 0.9651 - loss: 0.0997 - precision: 0.9683 - recall: 0.9618 - val_accuracy: 0.9131 - val_loss: 0.2842 - val_precision: 0.9185 - val_recall: 0.9081\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9067 - loss: 0.3142 - precision: 0.9109 - recall: 0.9044\n",
      "accuracy: 0.9054999947547913,\n",
      " precision: 0.911532998085022,\n",
      " recall: 0.9025999903678894\n"
     ]
    }
   ],
   "source": [
    "model2 = Model(inputs=inputs, outputs=outputs)\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',\n",
    "              metrics=['accuracy','precision','recall'])\n",
    "\n",
    "model2.fit(x_train2, y_train2, epochs=20, batch_size=128, validation_split=0.25, verbose=1)\n",
    "loss, acc, prec, rec = model2.evaluate(x_test2,y_test2)\n",
    "print(f'accuracy: {acc},\\n precision: {prec},\\n recall: {rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0273434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "[[840   0  33  14   1   1 103   0   8   0]\n",
      " [  1 983   2   9   2   0   1   0   2   0]\n",
      " [ 10   1 889   7  43   0  48   0   2   0]\n",
      " [ 21   2  17 901  30   0  27   0   2   0]\n",
      " [  2   1  51  25 864   1  53   0   3   0]\n",
      " [  0   0   0   0   0 989   0   4   0   7]\n",
      " [105   2  74  17  75   0 720   0   7   0]\n",
      " [  0   0   0   0   0  47   0 941   1  11]\n",
      " [  3   0   5   1   3   1   7   3 977   0]\n",
      " [  0   0   0   0   0   5   1  43   0 951]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      1000\n",
      "           1       0.99      0.98      0.99      1000\n",
      "           2       0.83      0.89      0.86      1000\n",
      "           3       0.93      0.90      0.91      1000\n",
      "           4       0.85      0.86      0.86      1000\n",
      "           5       0.95      0.99      0.97      1000\n",
      "           6       0.75      0.72      0.73      1000\n",
      "           7       0.95      0.94      0.95      1000\n",
      "           8       0.98      0.98      0.98      1000\n",
      "           9       0.98      0.95      0.97      1000\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred2 = model2.predict(x_test2)\n",
    "y_pred2 = np.argmax(pred2, axis=1)\n",
    "y_test2 = np.argmax(y_test2, axis=1)\n",
    "print(confusion_matrix(y_test2,y_pred2))\n",
    "print(classification_report(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad3a333",
   "metadata": {},
   "source": [
    "## CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21d390bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train3, y_train3), (x_test3, y_test3) = cifar10.load_data()\n",
    "num_classes = y_train3.max()-y_train3.min()+1\n",
    "x_train3 = x_train3.astype(\"float32\") / 255\n",
    "x_test3 = x_test3.astype(\"float32\") / 255\n",
    "y_train3 = to_categorical(y_train3, num_classes)\n",
    "y_test3 = to_categorical(y_test3, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d8dad",
   "metadata": {},
   "source": [
    "### NN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95d5a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=x_train3.shape[1:])\n",
    "x = Flatten()(inputs)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "outputs = Dense(10, activation=\"softmax\")(x)\n",
    "model0_3 = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1ca2a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - accuracy: 0.2248 - loss: 2.1348 - precision: 0.4399 - recall: 0.0222 - val_accuracy: 0.3530 - val_loss: 1.8018 - val_precision: 0.5650 - val_recall: 0.1206\n",
      "Epoch 2/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 74ms/step - accuracy: 0.3628 - loss: 1.7566 - precision: 0.6088 - recall: 0.1153 - val_accuracy: 0.3927 - val_loss: 1.7165 - val_precision: 0.5816 - val_recall: 0.1842\n",
      "Epoch 3/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 74ms/step - accuracy: 0.4039 - loss: 1.6526 - precision: 0.6319 - recall: 0.1605 - val_accuracy: 0.4198 - val_loss: 1.6262 - val_precision: 0.6780 - val_recall: 0.1521\n",
      "Epoch 4/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 72ms/step - accuracy: 0.4341 - loss: 1.5748 - precision: 0.6532 - recall: 0.1923 - val_accuracy: 0.4292 - val_loss: 1.5839 - val_precision: 0.6162 - val_recall: 0.2323\n",
      "Epoch 5/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 69ms/step - accuracy: 0.4571 - loss: 1.5158 - precision: 0.6718 - recall: 0.2318 - val_accuracy: 0.4352 - val_loss: 1.5696 - val_precision: 0.6489 - val_recall: 0.2207\n",
      "Epoch 6/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 80ms/step - accuracy: 0.4684 - loss: 1.4794 - precision: 0.6754 - recall: 0.2458 - val_accuracy: 0.4325 - val_loss: 1.6287 - val_precision: 0.6177 - val_recall: 0.2602\n",
      "Epoch 7/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - accuracy: 0.4844 - loss: 1.4384 - precision: 0.6812 - recall: 0.2699 - val_accuracy: 0.4671 - val_loss: 1.4983 - val_precision: 0.6520 - val_recall: 0.2603\n",
      "Epoch 8/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 74ms/step - accuracy: 0.5008 - loss: 1.3960 - precision: 0.6911 - recall: 0.2936 - val_accuracy: 0.4739 - val_loss: 1.4795 - val_precision: 0.6739 - val_recall: 0.2722\n",
      "Epoch 9/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 77ms/step - accuracy: 0.5112 - loss: 1.3589 - precision: 0.6985 - recall: 0.3105 - val_accuracy: 0.4738 - val_loss: 1.4917 - val_precision: 0.6579 - val_recall: 0.2872\n",
      "Epoch 10/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 80ms/step - accuracy: 0.5179 - loss: 1.3395 - precision: 0.6903 - recall: 0.3201 - val_accuracy: 0.4771 - val_loss: 1.4890 - val_precision: 0.6590 - val_recall: 0.2990\n",
      "Epoch 11/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 73ms/step - accuracy: 0.5390 - loss: 1.2905 - precision: 0.7152 - recall: 0.3456 - val_accuracy: 0.4826 - val_loss: 1.4466 - val_precision: 0.6716 - val_recall: 0.3053\n",
      "Epoch 12/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 82ms/step - accuracy: 0.5464 - loss: 1.2593 - precision: 0.7209 - recall: 0.3609 - val_accuracy: 0.4922 - val_loss: 1.4519 - val_precision: 0.6613 - val_recall: 0.3130\n",
      "Epoch 13/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 79ms/step - accuracy: 0.5594 - loss: 1.2165 - precision: 0.7290 - recall: 0.3832 - val_accuracy: 0.4906 - val_loss: 1.4588 - val_precision: 0.6522 - val_recall: 0.3291\n",
      "Epoch 14/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 82ms/step - accuracy: 0.5673 - loss: 1.1886 - precision: 0.7311 - recall: 0.3941 - val_accuracy: 0.4890 - val_loss: 1.4546 - val_precision: 0.6515 - val_recall: 0.3346\n",
      "Epoch 15/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - accuracy: 0.5843 - loss: 1.1490 - precision: 0.7379 - recall: 0.4186 - val_accuracy: 0.4888 - val_loss: 1.4650 - val_precision: 0.6269 - val_recall: 0.3505\n",
      "Epoch 16/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 75ms/step - accuracy: 0.5978 - loss: 1.1140 - precision: 0.7444 - recall: 0.4391 - val_accuracy: 0.5087 - val_loss: 1.4560 - val_precision: 0.6352 - val_recall: 0.3809\n",
      "Epoch 17/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 78ms/step - accuracy: 0.6170 - loss: 1.0616 - precision: 0.7552 - recall: 0.4674 - val_accuracy: 0.4971 - val_loss: 1.4873 - val_precision: 0.6293 - val_recall: 0.3720\n",
      "Epoch 18/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 77ms/step - accuracy: 0.6233 - loss: 1.0387 - precision: 0.7623 - recall: 0.4804 - val_accuracy: 0.5001 - val_loss: 1.5026 - val_precision: 0.6113 - val_recall: 0.3836\n",
      "Epoch 19/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 81ms/step - accuracy: 0.6397 - loss: 0.9992 - precision: 0.7715 - recall: 0.5050 - val_accuracy: 0.4889 - val_loss: 1.5783 - val_precision: 0.6039 - val_recall: 0.3800\n",
      "Epoch 20/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 78ms/step - accuracy: 0.6601 - loss: 0.9392 - precision: 0.7805 - recall: 0.5340 - val_accuracy: 0.4975 - val_loss: 1.5483 - val_precision: 0.6023 - val_recall: 0.3978\n",
      "Epoch 21/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 78ms/step - accuracy: 0.6780 - loss: 0.8856 - precision: 0.7922 - recall: 0.5614 - val_accuracy: 0.5014 - val_loss: 1.5913 - val_precision: 0.5951 - val_recall: 0.4085\n",
      "Epoch 22/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 90ms/step - accuracy: 0.6920 - loss: 0.8552 - precision: 0.7986 - recall: 0.5817 - val_accuracy: 0.4992 - val_loss: 1.6422 - val_precision: 0.5933 - val_recall: 0.4035\n",
      "Epoch 23/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 111ms/step - accuracy: 0.7061 - loss: 0.8078 - precision: 0.8077 - recall: 0.6063 - val_accuracy: 0.4931 - val_loss: 1.6767 - val_precision: 0.5848 - val_recall: 0.4006\n",
      "Epoch 24/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - accuracy: 0.7257 - loss: 0.7517 - precision: 0.8223 - recall: 0.6321 - val_accuracy: 0.4958 - val_loss: 1.7396 - val_precision: 0.5784 - val_recall: 0.4182\n",
      "Epoch 25/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.7407 - loss: 0.7147 - precision: 0.8311 - recall: 0.6522 - val_accuracy: 0.4979 - val_loss: 1.8122 - val_precision: 0.5647 - val_recall: 0.4276\n",
      "Epoch 26/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 75ms/step - accuracy: 0.7576 - loss: 0.6703 - precision: 0.8395 - recall: 0.6795 - val_accuracy: 0.4926 - val_loss: 1.8591 - val_precision: 0.5668 - val_recall: 0.4280\n",
      "Epoch 27/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 115ms/step - accuracy: 0.7768 - loss: 0.6205 - precision: 0.8504 - recall: 0.7060 - val_accuracy: 0.4920 - val_loss: 1.9925 - val_precision: 0.5505 - val_recall: 0.4324\n",
      "Epoch 28/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 91ms/step - accuracy: 0.7926 - loss: 0.5750 - precision: 0.8610 - recall: 0.7302 - val_accuracy: 0.4892 - val_loss: 2.0168 - val_precision: 0.5479 - val_recall: 0.4322\n",
      "Epoch 29/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - accuracy: 0.8038 - loss: 0.5389 - precision: 0.8681 - recall: 0.7461 - val_accuracy: 0.4910 - val_loss: 2.0703 - val_precision: 0.5488 - val_recall: 0.4371\n",
      "Epoch 30/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 85ms/step - accuracy: 0.8188 - loss: 0.5057 - precision: 0.8739 - recall: 0.7626 - val_accuracy: 0.4827 - val_loss: 2.2610 - val_precision: 0.5296 - val_recall: 0.4398\n",
      "Epoch 31/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - accuracy: 0.8252 - loss: 0.4829 - precision: 0.8769 - recall: 0.7747 - val_accuracy: 0.4892 - val_loss: 2.3194 - val_precision: 0.5321 - val_recall: 0.4470\n",
      "Epoch 32/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 87ms/step - accuracy: 0.8335 - loss: 0.4626 - precision: 0.8819 - recall: 0.7893 - val_accuracy: 0.4869 - val_loss: 2.3663 - val_precision: 0.5304 - val_recall: 0.4500\n",
      "Epoch 33/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 87ms/step - accuracy: 0.8498 - loss: 0.4273 - precision: 0.8925 - recall: 0.8071 - val_accuracy: 0.4795 - val_loss: 2.4798 - val_precision: 0.5199 - val_recall: 0.4378\n",
      "Epoch 34/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 87ms/step - accuracy: 0.8558 - loss: 0.3988 - precision: 0.8972 - recall: 0.8193 - val_accuracy: 0.4872 - val_loss: 2.5373 - val_precision: 0.5251 - val_recall: 0.4503\n",
      "Epoch 35/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.8622 - loss: 0.3852 - precision: 0.9011 - recall: 0.8264 - val_accuracy: 0.4799 - val_loss: 2.7886 - val_precision: 0.5142 - val_recall: 0.4498\n",
      "Epoch 36/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - accuracy: 0.8714 - loss: 0.3577 - precision: 0.9048 - recall: 0.8405 - val_accuracy: 0.4782 - val_loss: 2.7500 - val_precision: 0.5107 - val_recall: 0.4441\n",
      "Epoch 37/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 85ms/step - accuracy: 0.8760 - loss: 0.3459 - precision: 0.9072 - recall: 0.8442 - val_accuracy: 0.4853 - val_loss: 2.8917 - val_precision: 0.5141 - val_recall: 0.4590\n",
      "Epoch 38/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 77ms/step - accuracy: 0.8801 - loss: 0.3322 - precision: 0.9087 - recall: 0.8555 - val_accuracy: 0.4802 - val_loss: 2.9287 - val_precision: 0.5085 - val_recall: 0.4545\n",
      "Epoch 39/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.8840 - loss: 0.3228 - precision: 0.9099 - recall: 0.8587 - val_accuracy: 0.4824 - val_loss: 2.9471 - val_precision: 0.5120 - val_recall: 0.4574\n",
      "Epoch 40/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.9021 - loss: 0.2775 - precision: 0.9261 - recall: 0.8807 - val_accuracy: 0.4850 - val_loss: 3.2796 - val_precision: 0.5054 - val_recall: 0.4619\n",
      "Epoch 41/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.9093 - loss: 0.2576 - precision: 0.9294 - recall: 0.8913 - val_accuracy: 0.4646 - val_loss: 3.2180 - val_precision: 0.4908 - val_recall: 0.4401\n",
      "Epoch 42/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 95ms/step - accuracy: 0.8942 - loss: 0.2944 - precision: 0.9168 - recall: 0.8721 - val_accuracy: 0.4802 - val_loss: 3.0838 - val_precision: 0.5065 - val_recall: 0.4538\n",
      "Epoch 43/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 95ms/step - accuracy: 0.9084 - loss: 0.2608 - precision: 0.9283 - recall: 0.8882 - val_accuracy: 0.4842 - val_loss: 3.5432 - val_precision: 0.5013 - val_recall: 0.4650\n",
      "Epoch 44/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 90ms/step - accuracy: 0.9162 - loss: 0.2374 - precision: 0.9330 - recall: 0.9012 - val_accuracy: 0.4663 - val_loss: 3.4775 - val_precision: 0.4890 - val_recall: 0.4497\n",
      "Epoch 45/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - accuracy: 0.9084 - loss: 0.2599 - precision: 0.9267 - recall: 0.8897 - val_accuracy: 0.4834 - val_loss: 3.4724 - val_precision: 0.5023 - val_recall: 0.4636\n",
      "Epoch 46/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 82ms/step - accuracy: 0.9009 - loss: 0.2885 - precision: 0.9195 - recall: 0.8831 - val_accuracy: 0.4819 - val_loss: 3.5011 - val_precision: 0.4999 - val_recall: 0.4619\n",
      "Epoch 47/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 79ms/step - accuracy: 0.9270 - loss: 0.2145 - precision: 0.9385 - recall: 0.9128 - val_accuracy: 0.4712 - val_loss: 3.7498 - val_precision: 0.4889 - val_recall: 0.4547\n",
      "Epoch 48/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - accuracy: 0.9091 - loss: 0.2534 - precision: 0.9259 - recall: 0.8954 - val_accuracy: 0.4754 - val_loss: 3.8406 - val_precision: 0.4918 - val_recall: 0.4607\n",
      "Epoch 49/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - accuracy: 0.9291 - loss: 0.2064 - precision: 0.9401 - recall: 0.9172 - val_accuracy: 0.4730 - val_loss: 3.8609 - val_precision: 0.4910 - val_recall: 0.4579\n",
      "Epoch 50/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 76ms/step - accuracy: 0.9217 - loss: 0.2232 - precision: 0.9347 - recall: 0.9093 - val_accuracy: 0.4708 - val_loss: 3.8393 - val_precision: 0.4895 - val_recall: 0.4558\n",
      "Epoch 51/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 89ms/step - accuracy: 0.9319 - loss: 0.1979 - precision: 0.9429 - recall: 0.9211 - val_accuracy: 0.4611 - val_loss: 3.9971 - val_precision: 0.4774 - val_recall: 0.4476\n",
      "Epoch 52/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 92ms/step - accuracy: 0.9196 - loss: 0.2271 - precision: 0.9317 - recall: 0.9095 - val_accuracy: 0.4720 - val_loss: 3.9330 - val_precision: 0.4883 - val_recall: 0.4565\n",
      "Epoch 53/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - accuracy: 0.9234 - loss: 0.2222 - precision: 0.9352 - recall: 0.9123 - val_accuracy: 0.4757 - val_loss: 4.2214 - val_precision: 0.4890 - val_recall: 0.4644\n",
      "Epoch 54/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.9388 - loss: 0.1798 - precision: 0.9480 - recall: 0.9299 - val_accuracy: 0.4716 - val_loss: 4.0154 - val_precision: 0.4867 - val_recall: 0.4570\n",
      "Epoch 55/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 90ms/step - accuracy: 0.9307 - loss: 0.2023 - precision: 0.9409 - recall: 0.9205 - val_accuracy: 0.4784 - val_loss: 4.1989 - val_precision: 0.4928 - val_recall: 0.4674\n",
      "Epoch 56/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 96ms/step - accuracy: 0.9340 - loss: 0.1848 - precision: 0.9428 - recall: 0.9261 - val_accuracy: 0.4782 - val_loss: 4.1561 - val_precision: 0.4940 - val_recall: 0.4645\n",
      "Epoch 57/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - accuracy: 0.9326 - loss: 0.1961 - precision: 0.9427 - recall: 0.9243 - val_accuracy: 0.4722 - val_loss: 4.2872 - val_precision: 0.4853 - val_recall: 0.4594\n",
      "Epoch 58/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 80ms/step - accuracy: 0.9388 - loss: 0.1753 - precision: 0.9477 - recall: 0.9316 - val_accuracy: 0.4658 - val_loss: 4.6991 - val_precision: 0.4778 - val_recall: 0.4553\n",
      "Epoch 59/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 83ms/step - accuracy: 0.9351 - loss: 0.1820 - precision: 0.9429 - recall: 0.9278 - val_accuracy: 0.4694 - val_loss: 4.4241 - val_precision: 0.4808 - val_recall: 0.4574\n",
      "Epoch 60/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 87ms/step - accuracy: 0.9265 - loss: 0.2159 - precision: 0.9368 - recall: 0.9180 - val_accuracy: 0.4769 - val_loss: 4.2009 - val_precision: 0.4910 - val_recall: 0.4649\n",
      "Epoch 61/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 80ms/step - accuracy: 0.9466 - loss: 0.1555 - precision: 0.9537 - recall: 0.9405 - val_accuracy: 0.4757 - val_loss: 4.6036 - val_precision: 0.4884 - val_recall: 0.4662\n",
      "Epoch 62/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 82ms/step - accuracy: 0.9562 - loss: 0.1255 - precision: 0.9620 - recall: 0.9514 - val_accuracy: 0.4761 - val_loss: 4.4775 - val_precision: 0.4879 - val_recall: 0.4642\n",
      "Epoch 63/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 87ms/step - accuracy: 0.9415 - loss: 0.1769 - precision: 0.9485 - recall: 0.9347 - val_accuracy: 0.4762 - val_loss: 4.7143 - val_precision: 0.4863 - val_recall: 0.4657\n",
      "Epoch 64/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 77ms/step - accuracy: 0.9390 - loss: 0.1817 - precision: 0.9465 - recall: 0.9329 - val_accuracy: 0.4765 - val_loss: 4.6179 - val_precision: 0.4876 - val_recall: 0.4674\n",
      "Epoch 65/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 86ms/step - accuracy: 0.9466 - loss: 0.1605 - precision: 0.9538 - recall: 0.9405 - val_accuracy: 0.4598 - val_loss: 4.8083 - val_precision: 0.4717 - val_recall: 0.4490\n",
      "Epoch 66/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.9244 - loss: 0.2210 - precision: 0.9329 - recall: 0.9171 - val_accuracy: 0.4754 - val_loss: 4.5819 - val_precision: 0.4864 - val_recall: 0.4646\n",
      "Epoch 67/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 81ms/step - accuracy: 0.9403 - loss: 0.1747 - precision: 0.9476 - recall: 0.9336 - val_accuracy: 0.4672 - val_loss: 4.6850 - val_precision: 0.4776 - val_recall: 0.4573\n",
      "Epoch 68/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 80ms/step - accuracy: 0.9517 - loss: 0.1452 - precision: 0.9586 - recall: 0.9453 - val_accuracy: 0.4724 - val_loss: 4.8044 - val_precision: 0.4851 - val_recall: 0.4619\n",
      "Epoch 69/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 90ms/step - accuracy: 0.9459 - loss: 0.1587 - precision: 0.9520 - recall: 0.9403 - val_accuracy: 0.4738 - val_loss: 4.9363 - val_precision: 0.4849 - val_recall: 0.4659\n",
      "Epoch 70/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 80ms/step - accuracy: 0.9469 - loss: 0.1610 - precision: 0.9519 - recall: 0.9413 - val_accuracy: 0.4649 - val_loss: 4.9108 - val_precision: 0.4771 - val_recall: 0.4562\n",
      "Epoch 71/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.9374 - loss: 0.1905 - precision: 0.9445 - recall: 0.9319 - val_accuracy: 0.4702 - val_loss: 4.8065 - val_precision: 0.4813 - val_recall: 0.4614\n",
      "Epoch 72/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - accuracy: 0.9520 - loss: 0.1432 - precision: 0.9561 - recall: 0.9480 - val_accuracy: 0.4746 - val_loss: 4.9426 - val_precision: 0.4837 - val_recall: 0.4655\n",
      "Epoch 73/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 87ms/step - accuracy: 0.9437 - loss: 0.1674 - precision: 0.9490 - recall: 0.9392 - val_accuracy: 0.4724 - val_loss: 4.9151 - val_precision: 0.4846 - val_recall: 0.4642\n",
      "Epoch 74/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 85ms/step - accuracy: 0.9479 - loss: 0.1598 - precision: 0.9528 - recall: 0.9432 - val_accuracy: 0.4645 - val_loss: 5.2514 - val_precision: 0.4742 - val_recall: 0.4562\n",
      "Epoch 75/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 85ms/step - accuracy: 0.9384 - loss: 0.1812 - precision: 0.9452 - recall: 0.9341 - val_accuracy: 0.4798 - val_loss: 5.0083 - val_precision: 0.4893 - val_recall: 0.4709\n",
      "Epoch 76/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 89ms/step - accuracy: 0.9581 - loss: 0.1255 - precision: 0.9624 - recall: 0.9542 - val_accuracy: 0.4677 - val_loss: 5.3767 - val_precision: 0.4757 - val_recall: 0.4612\n",
      "Epoch 77/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 86ms/step - accuracy: 0.9568 - loss: 0.1297 - precision: 0.9608 - recall: 0.9528 - val_accuracy: 0.4690 - val_loss: 5.0483 - val_precision: 0.4800 - val_recall: 0.4607\n",
      "Epoch 78/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.9489 - loss: 0.1505 - precision: 0.9541 - recall: 0.9442 - val_accuracy: 0.4745 - val_loss: 5.2165 - val_precision: 0.4816 - val_recall: 0.4650\n",
      "Epoch 79/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 86ms/step - accuracy: 0.9479 - loss: 0.1553 - precision: 0.9529 - recall: 0.9441 - val_accuracy: 0.4766 - val_loss: 4.9458 - val_precision: 0.4853 - val_recall: 0.4677\n",
      "Epoch 80/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 89ms/step - accuracy: 0.9384 - loss: 0.1876 - precision: 0.9439 - recall: 0.9335 - val_accuracy: 0.4749 - val_loss: 5.2879 - val_precision: 0.4835 - val_recall: 0.4662\n",
      "Epoch 81/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 85ms/step - accuracy: 0.9744 - loss: 0.0753 - precision: 0.9768 - recall: 0.9714 - val_accuracy: 0.4751 - val_loss: 5.5168 - val_precision: 0.4836 - val_recall: 0.4686\n",
      "Epoch 82/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 85ms/step - accuracy: 0.9542 - loss: 0.1368 - precision: 0.9580 - recall: 0.9514 - val_accuracy: 0.4620 - val_loss: 5.2598 - val_precision: 0.4713 - val_recall: 0.4533\n",
      "Epoch 83/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - accuracy: 0.9279 - loss: 0.2284 - precision: 0.9349 - recall: 0.9229 - val_accuracy: 0.4678 - val_loss: 5.1915 - val_precision: 0.4786 - val_recall: 0.4594\n",
      "Epoch 84/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 92ms/step - accuracy: 0.9519 - loss: 0.1471 - precision: 0.9559 - recall: 0.9479 - val_accuracy: 0.4686 - val_loss: 5.5297 - val_precision: 0.4781 - val_recall: 0.4619\n",
      "Epoch 85/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 89ms/step - accuracy: 0.9582 - loss: 0.1271 - precision: 0.9612 - recall: 0.9551 - val_accuracy: 0.4718 - val_loss: 5.4608 - val_precision: 0.4792 - val_recall: 0.4637\n",
      "Epoch 86/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 89ms/step - accuracy: 0.9576 - loss: 0.1281 - precision: 0.9604 - recall: 0.9542 - val_accuracy: 0.4708 - val_loss: 5.5127 - val_precision: 0.4784 - val_recall: 0.4632\n",
      "Epoch 87/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 87ms/step - accuracy: 0.9480 - loss: 0.1657 - precision: 0.9532 - recall: 0.9439 - val_accuracy: 0.4733 - val_loss: 5.6003 - val_precision: 0.4821 - val_recall: 0.4662\n",
      "Epoch 88/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - accuracy: 0.9529 - loss: 0.1415 - precision: 0.9572 - recall: 0.9494 - val_accuracy: 0.4750 - val_loss: 5.5469 - val_precision: 0.4827 - val_recall: 0.4684\n",
      "Epoch 89/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - accuracy: 0.9586 - loss: 0.1241 - precision: 0.9621 - recall: 0.9557 - val_accuracy: 0.4710 - val_loss: 5.5844 - val_precision: 0.4803 - val_recall: 0.4653\n",
      "Epoch 90/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 83ms/step - accuracy: 0.9546 - loss: 0.1425 - precision: 0.9587 - recall: 0.9513 - val_accuracy: 0.4695 - val_loss: 5.7242 - val_precision: 0.4778 - val_recall: 0.4630\n",
      "Epoch 91/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 81ms/step - accuracy: 0.9524 - loss: 0.1466 - precision: 0.9562 - recall: 0.9493 - val_accuracy: 0.4706 - val_loss: 5.5799 - val_precision: 0.4800 - val_recall: 0.4637\n",
      "Epoch 92/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.9670 - loss: 0.1031 - precision: 0.9692 - recall: 0.9633 - val_accuracy: 0.4787 - val_loss: 5.7738 - val_precision: 0.4858 - val_recall: 0.4720\n",
      "Epoch 93/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.9457 - loss: 0.1687 - precision: 0.9496 - recall: 0.9424 - val_accuracy: 0.4730 - val_loss: 5.4313 - val_precision: 0.4814 - val_recall: 0.4658\n",
      "Epoch 94/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.9513 - loss: 0.1566 - precision: 0.9554 - recall: 0.9475 - val_accuracy: 0.4639 - val_loss: 5.6988 - val_precision: 0.4734 - val_recall: 0.4570\n",
      "Epoch 95/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.9554 - loss: 0.1324 - precision: 0.9596 - recall: 0.9517 - val_accuracy: 0.4734 - val_loss: 5.7659 - val_precision: 0.4808 - val_recall: 0.4658\n",
      "Epoch 96/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - accuracy: 0.9561 - loss: 0.1353 - precision: 0.9600 - recall: 0.9534 - val_accuracy: 0.4643 - val_loss: 5.6171 - val_precision: 0.4741 - val_recall: 0.4587\n",
      "Epoch 97/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 86ms/step - accuracy: 0.9522 - loss: 0.1578 - precision: 0.9563 - recall: 0.9490 - val_accuracy: 0.4712 - val_loss: 5.6733 - val_precision: 0.4805 - val_recall: 0.4651\n",
      "Epoch 98/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 85ms/step - accuracy: 0.9530 - loss: 0.1488 - precision: 0.9565 - recall: 0.9497 - val_accuracy: 0.4749 - val_loss: 5.8183 - val_precision: 0.4831 - val_recall: 0.4695\n",
      "Epoch 99/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 86ms/step - accuracy: 0.9715 - loss: 0.0884 - precision: 0.9743 - recall: 0.9691 - val_accuracy: 0.4703 - val_loss: 6.0116 - val_precision: 0.4782 - val_recall: 0.4639\n",
      "Epoch 100/100\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 85ms/step - accuracy: 0.9705 - loss: 0.0926 - precision: 0.9732 - recall: 0.9687 - val_accuracy: 0.4676 - val_loss: 5.7363 - val_precision: 0.4759 - val_recall: 0.4613\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.4761 - loss: 5.5150 - precision: 0.4842 - recall: 0.4690\n",
      "accuracy: 0.4702000021934509,\n",
      " precision: 0.47878599166870117,\n",
      " recall: 0.46380001306533813\n"
     ]
    }
   ],
   "source": [
    "model0_3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", \n",
    "               metrics=['accuracy','precision','recall'])\n",
    "model0_3.fit(x_train3, y_train3, epochs=100, batch_size=128, validation_split=0.25, verbose=1)\n",
    "loss, acc, prec, rec = model0_3.evaluate(x_test3,y_test3)\n",
    "print(f'accuracy: {acc},\\n precision: {prec},\\n recall: {rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "741b79b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
      "[[595  27  43  46  35  31  21  32 113  57]\n",
      " [ 55 540  15  19  22  27  22  29  65 206]\n",
      " [ 86  21 363 111 127 100  94  56  20  22]\n",
      " [ 37  21 109 317  77 173 135  48  33  50]\n",
      " [ 63  10 179  75 364  67 134  69  22  17]\n",
      " [ 37   9 101 225  92 347  85  54  24  26]\n",
      " [ 15  12 121  99 113  49 547  19   6  19]\n",
      " [ 61  14  71  74  84 101  31 497  20  47]\n",
      " [117  71  24  33  30  16  14  18 610  67]\n",
      " [ 67 159  22  34  25  28  30  36  77 522]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.59      0.56      1000\n",
      "           1       0.61      0.54      0.57      1000\n",
      "           2       0.35      0.36      0.35      1000\n",
      "           3       0.31      0.32      0.31      1000\n",
      "           4       0.38      0.36      0.37      1000\n",
      "           5       0.37      0.35      0.36      1000\n",
      "           6       0.49      0.55      0.52      1000\n",
      "           7       0.58      0.50      0.53      1000\n",
      "           8       0.62      0.61      0.61      1000\n",
      "           9       0.51      0.52      0.51      1000\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.47      0.47      0.47     10000\n",
      "weighted avg       0.47      0.47      0.47     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred3 = model0_3.predict(x_test3)\n",
    "y_pred3 = np.argmax(pred3, axis=1)\n",
    "y_test03 = np.argmax(y_test3, axis=1)\n",
    "print(confusion_matrix(y_test03,y_pred3))\n",
    "print(classification_report(y_test03, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5de4c0",
   "metadata": {},
   "source": [
    "### CNN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b5e1fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 111ms/step - accuracy: 0.3030 - loss: 1.9025 - precision: 0.5587 - recall: 0.0530 - val_accuracy: 0.4840 - val_loss: 1.4455 - val_precision: 0.7061 - val_recall: 0.2089\n",
      "Epoch 2/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - accuracy: 0.5033 - loss: 1.3864 - precision: 0.7138 - recall: 0.2711 - val_accuracy: 0.5490 - val_loss: 1.2856 - val_precision: 0.7219 - val_recall: 0.3387\n",
      "Epoch 3/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 87ms/step - accuracy: 0.5666 - loss: 1.2102 - precision: 0.7423 - recall: 0.3785 - val_accuracy: 0.5756 - val_loss: 1.2008 - val_precision: 0.7155 - val_recall: 0.4106\n",
      "Epoch 4/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 89ms/step - accuracy: 0.6153 - loss: 1.1022 - precision: 0.7635 - recall: 0.4492 - val_accuracy: 0.6202 - val_loss: 1.0918 - val_precision: 0.7580 - val_recall: 0.4626\n",
      "Epoch 5/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 90ms/step - accuracy: 0.6515 - loss: 1.0006 - precision: 0.7858 - recall: 0.5090 - val_accuracy: 0.6354 - val_loss: 1.0529 - val_precision: 0.7636 - val_recall: 0.4936\n",
      "Epoch 6/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 88ms/step - accuracy: 0.6675 - loss: 0.9516 - precision: 0.7916 - recall: 0.5409 - val_accuracy: 0.6474 - val_loss: 0.9989 - val_precision: 0.7658 - val_recall: 0.5271\n",
      "Epoch 7/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 89ms/step - accuracy: 0.6873 - loss: 0.9010 - precision: 0.8009 - recall: 0.5707 - val_accuracy: 0.6618 - val_loss: 0.9880 - val_precision: 0.7754 - val_recall: 0.5468\n",
      "Epoch 8/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 93ms/step - accuracy: 0.7084 - loss: 0.8460 - precision: 0.8080 - recall: 0.5965 - val_accuracy: 0.6654 - val_loss: 0.9555 - val_precision: 0.7728 - val_recall: 0.5610\n",
      "Epoch 9/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 97ms/step - accuracy: 0.7200 - loss: 0.8078 - precision: 0.8177 - recall: 0.6218 - val_accuracy: 0.6689 - val_loss: 0.9690 - val_precision: 0.7619 - val_recall: 0.5736\n",
      "Epoch 10/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 113ms/step - accuracy: 0.7366 - loss: 0.7626 - precision: 0.8284 - recall: 0.6490 - val_accuracy: 0.6666 - val_loss: 0.9823 - val_precision: 0.7652 - val_recall: 0.5758\n",
      "Epoch 11/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 110ms/step - accuracy: 0.7463 - loss: 0.7288 - precision: 0.8356 - recall: 0.6597 - val_accuracy: 0.6923 - val_loss: 0.9061 - val_precision: 0.7823 - val_recall: 0.6093\n",
      "Epoch 12/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - accuracy: 0.7603 - loss: 0.6991 - precision: 0.8413 - recall: 0.6793 - val_accuracy: 0.6992 - val_loss: 0.8854 - val_precision: 0.7761 - val_recall: 0.6199\n",
      "Epoch 13/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 103ms/step - accuracy: 0.7755 - loss: 0.6627 - precision: 0.8460 - recall: 0.6957 - val_accuracy: 0.6939 - val_loss: 0.9050 - val_precision: 0.7714 - val_recall: 0.6175\n",
      "Epoch 14/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - accuracy: 0.7872 - loss: 0.6294 - precision: 0.8574 - recall: 0.7151 - val_accuracy: 0.7054 - val_loss: 0.8869 - val_precision: 0.7758 - val_recall: 0.6429\n",
      "Epoch 15/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 97ms/step - accuracy: 0.7984 - loss: 0.5992 - precision: 0.8627 - recall: 0.7318 - val_accuracy: 0.7046 - val_loss: 0.8820 - val_precision: 0.7704 - val_recall: 0.6392\n",
      "Epoch 16/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 109ms/step - accuracy: 0.8021 - loss: 0.5743 - precision: 0.8672 - recall: 0.7405 - val_accuracy: 0.6966 - val_loss: 0.9123 - val_precision: 0.7535 - val_recall: 0.6426\n",
      "Epoch 17/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 103ms/step - accuracy: 0.8108 - loss: 0.5500 - precision: 0.8686 - recall: 0.7546 - val_accuracy: 0.7040 - val_loss: 0.9098 - val_precision: 0.7637 - val_recall: 0.6498\n",
      "Epoch 18/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - accuracy: 0.8234 - loss: 0.5236 - precision: 0.8779 - recall: 0.7697 - val_accuracy: 0.7078 - val_loss: 0.9116 - val_precision: 0.7602 - val_recall: 0.6606\n",
      "Epoch 19/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - accuracy: 0.8350 - loss: 0.4894 - precision: 0.8829 - recall: 0.7863 - val_accuracy: 0.7075 - val_loss: 0.9047 - val_precision: 0.7609 - val_recall: 0.6594\n",
      "Epoch 20/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 103ms/step - accuracy: 0.8428 - loss: 0.4650 - precision: 0.8908 - recall: 0.7961 - val_accuracy: 0.7138 - val_loss: 0.9227 - val_precision: 0.7608 - val_recall: 0.6739\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7111 - loss: 0.9087 - precision: 0.7650 - recall: 0.6782\n",
      "accuracy: 0.7073000073432922,\n",
      " precision: 0.7596566677093506,\n",
      " recall: 0.6725999712944031\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=x_train3.shape[1:])\n",
    "x = Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(10, activation=\"softmax\")(x)\n",
    "model3 = Model(inputs=inputs, outputs=outputs)\n",
    "model3.compile(optimizer='adam',loss='categorical_crossentropy',\n",
    "              metrics=['accuracy','precision','recall'])\n",
    "\n",
    "model3.fit(x_train3, y_train3, epochs=20, batch_size=128, validation_split=0.25, verbose=1)\n",
    "loss, acc, prec, rec = model3.evaluate(x_test3,y_test3)\n",
    "print(f'accuracy: {acc},\\n precision: {prec},\\n recall: {rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9012086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
      "[[794  25  27   9  11   7  13   6  73  35]\n",
      " [ 27 838   2   8   1   7  11   4  30  72]\n",
      " [ 94  19 534  65  81  78  68  34  14  13]\n",
      " [ 34  17  57 496  68 186  64  28  26  24]\n",
      " [ 35  11  66  64 631  41  56  67  15  14]\n",
      " [ 17   5  45 154  40 642  26  48  15   8]\n",
      " [ 10   7  37  56  25  25 818  11   8   3]\n",
      " [ 35   5  15  43  73  71  10 716   6  26]\n",
      " [ 66  43   5   9   1   7   3   5 833  28]\n",
      " [ 31 116   4  12   6   7   7  11  35 771]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74      1000\n",
      "           1       0.77      0.84      0.80      1000\n",
      "           2       0.67      0.53      0.60      1000\n",
      "           3       0.54      0.50      0.52      1000\n",
      "           4       0.67      0.63      0.65      1000\n",
      "           5       0.60      0.64      0.62      1000\n",
      "           6       0.76      0.82      0.79      1000\n",
      "           7       0.77      0.72      0.74      1000\n",
      "           8       0.79      0.83      0.81      1000\n",
      "           9       0.78      0.77      0.77      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred3 = model3.predict(x_test3)\n",
    "y_pred3 = np.argmax(pred3, axis=1)\n",
    "y_test3 = np.argmax(y_test3, axis=1)\n",
    "print(confusion_matrix(y_test3,y_pred3))\n",
    "print(classification_report(y_test3, y_pred3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
